{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de Utilidades de Películas\n",
    "\n",
    "En primer lugar se cargaron los archivos de datos.\n",
    "\n",
    "El conjunto de entrada X corresponde a un dataset disperso o *sparse* lo que significa que tiene una gran cantidad de elementos iguales a cero. Por tanto es importante mantener esta matriz en formato disperso para usar menos memoria haciendo uso de compresión y usar algoritmos eficientes para estas matrices para distintas operaciones. \n",
    "\n",
    "En este caso se cargaron las matrices en formato csc_matrix (*Compressed Sparse Column matrix*) de forma de acelerar operaciones sobre columnas.\n",
    "\n",
    "La entrada considera 145256 características. El conjunto de entrenamiento consta de 1147 ejemplos, el de validación 317 y el de pruebas 254."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando set de entrenamiento...\n",
      "Cargando set de validacion...\n",
      "Cargando set de prueba...\n",
      "Conjuntos cargados\n",
      "(1147, 145256)\n",
      "(317, 145256)\n",
      "(254, 145256)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, csc_matrix\n",
    "from scipy.io import mmread\n",
    "\n",
    "\n",
    "\n",
    "print \"Cargando set de entrenamiento...\"\n",
    "X = csc_matrix(mmread('train.x.mm'))\n",
    "y = np.loadtxt('train.y.dat')\n",
    "print \"Cargando set de validacion...\"\n",
    "Xv = csc_matrix(mmread('dev.x.mm'))\n",
    "yv = np.loadtxt('dev.y.dat')\n",
    "print \"Cargando set de prueba...\"\n",
    "Xt = csc_matrix(mmread('test.x.mm'))\n",
    "yt = np.loadtxt('test.y.dat')\n",
    "print \"Conjuntos cargados\"\n",
    "\n",
    "print X.shape\n",
    "print Xv.shape\n",
    "print Xt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener una meta inicial se aplicó directamente sobre el conjunto una regresión lineal sin ninguna preparación de los datos de forma de obtener un coeficiente de determinación inicial sobre el conjunto de pruebas el cual mejorar. Se puede ver que al aplicar este enfoque se produce un sobre-ajuste.\n",
    "\n",
    "$R^2$ sobre el conjunto de entrenamiento es igual o muy cercano a $1$, sin embargo, tanto sobre el conjunto de validación como del conjunto de pruebas éste se acerca solo a $0.60$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training R2=1.000000\n",
      "validate R2=0.612864\n",
      "test R2=0.590315\n"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model as lm\n",
    "\n",
    "linreg = lm.LinearRegression(fit_intercept=False)\n",
    "linreg.fit(X,y)\n",
    "\n",
    "print \"training R2=%f\"%linreg.score(X,y)\n",
    "print \"validate R2=%f\"%linreg.score(Xv,yv)\n",
    "print \"test R2=%f\"%linreg.score(Xt,yt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Se probaron distintos enfoques. Los más destacables siendo:\n",
    "\n",
    "- Umbral de varianza\n",
    "- Forward Stepwise Selection\n",
    "- Regresión Lasso\n",
    "\n",
    "No obstante ningún enfoque logro una mejora substancial sobre la regresión lineal anteriormente vista."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Umbral de Varianza\n",
    "\n",
    "Umbral de varianza es una tipo de selección de características básico que remueve aquellas características de baja varianza con la idea de que estas no tendrán tanta influencia sobre la solución. Un caso extremo es cuando una característica tenga varianza igual a cero, se puede remover con seguridad puesto que todos sus valores son iguales.\n",
    "\n",
    "Se probaron umbrales de $0.5$, $0.1$, $0.01$ y $0.001$ y se calcularon los coeficientes de determinación. Se puede ver que se puede remover una gran cantidad de variables (pasando de 145256 a 58685) sin tener un cambio significativo de $R^2$ sobre todos los conjuntos. Sin embargo al reducir por este criterio aún más características el $R^2$ se reduce enormemente sobre los conjuntos de validación y entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1147, 1087)\n",
      "training R2=0.991065\n",
      "validate R2=-1.346798\n",
      "test R2=-0.464357\n",
      "(1147, 6214)\n",
      "training R2=1.000000\n",
      "validate R2=0.567887\n",
      "test R2=0.553110\n",
      "(1147, 58685)\n",
      "training R2=1.000000\n",
      "validate R2=0.611514\n",
      "test R2=0.593959\n",
      "(1147, 145222)\n",
      "training R2=1.000000\n",
      "validate R2=0.612862\n",
      "test R2=0.590313\n"
     ]
    }
   ],
   "source": [
    "import sklearn.feature_selection as fs\n",
    "\n",
    "selector = fs.VarianceThreshold(threshold=0.5)\n",
    "Xn = selector.fit_transform(X)\n",
    "Xnt = selector.transform(Xt); Xnv = selector.transform(Xv)\n",
    "linreg.fit(Xn,y)\n",
    "print Xn.shape\n",
    "print \"training R2=%f\"%linreg.score(Xn,y)\n",
    "print \"validate R2=%f\"%linreg.score(Xnv,yv)\n",
    "print \"test R2=%f\"%linreg.score(Xnt,yt)\n",
    "\n",
    "selector = fs.VarianceThreshold(threshold=0.1)\n",
    "Xn = selector.fit_transform(X)\n",
    "Xnt = selector.transform(Xt); Xnv = selector.transform(Xv)\n",
    "linreg.fit(Xn,y)\n",
    "print Xn.shape\n",
    "print \"training R2=%f\"%linreg.score(Xn,y)\n",
    "print \"validate R2=%f\"%linreg.score(Xnv,yv)\n",
    "print \"test R2=%f\"%linreg.score(Xnt,yt)\n",
    "\n",
    "selector = fs.VarianceThreshold(threshold=0.01)\n",
    "Xn = selector.fit_transform(X)\n",
    "Xnt = selector.transform(Xt); Xnv = selector.transform(Xv)\n",
    "linreg.fit(Xn,y)\n",
    "print Xn.shape\n",
    "print \"training R2=%f\"%linreg.score(Xn,y)\n",
    "print \"validate R2=%f\"%linreg.score(Xnv,yv)\n",
    "print \"test R2=%f\"%linreg.score(Xnt,yt)\n",
    "\n",
    "selector = fs.VarianceThreshold(threshold=0.001)\n",
    "Xn = selector.fit_transform(X)\n",
    "Xnt = selector.transform(Xt); Xnv = selector.transform(Xv)\n",
    "linreg.fit(Xn,y)\n",
    "print Xn.shape\n",
    "print \"training R2=%f\"%linreg.score(Xn,y)\n",
    "print \"validate R2=%f\"%linreg.score(Xnv,yv)\n",
    "print \"test R2=%f\"%linreg.score(Xnt,yt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Forward Stepwise Selection\n",
    "\n",
    "Se aplicó también FSS. Sin embargo, por eficiencia no se aplicó directamente sobre todo el conjunto de características. En lugar de eso, en cada iteración se tomaban aleatoriamente 10 características aún no integradas en el modelo y se integraba la mejor. \n",
    "\n",
    "Se probó el puntaje de coeficientes del modelo\n",
    "\n",
    "El proceso se detenía si encontraba un modelo con $R^2$ mayor a $0.6$ sobre el conjunto de pruebas (notar que solo se aprovechaba como criterio de parada, no para la construcción del modelo). Además el proceso también se detenía luego de la inclusión de 1000 características por temas de eficiencia pues en este punto cada generación del modelo tomaba más tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Coeficientes del modelo\n",
    "\n",
    "Al hacer uso de los coeficientes del modelo al integrar una característica se esperaba llegar a un modelo que ingresara aquellas características con influencia sobre la respuesta.\n",
    "\n",
    "Así el puntaje era calculado como: \n",
    "```python\n",
    "#indexes los indices de las características ingresadas al modelo en esta iteración más el candidato\n",
    "score = abs(model.coef_[indexes.index(candidate)])\n",
    "```\n",
    "Este enfoque provoco un fuerte sobre-ajuste del conjunto de entrenamiento.\n",
    "\n",
    "```\n",
    "#Salida de FSS usando coeficientes del modelo\n",
    "...\n",
    "R2test = -0.661601\n",
    "selected = 132655 ...\n",
    "totalvars=1000, R2train = 0.999654, R2val = -0.974732\n",
    "R2test = -0.673779\n",
    "selected = 110725 ...\n",
    "totalvars=1001, R2train = 0.999654, R2val = -0.965488\n",
    "R2test = -0.658075\n",
    "training R2=0.999654\n",
    "validate R2=-0.965488\n",
    "test R2=-0.658075\n",
    "```\n",
    "Se puede ver que habiendo agregado un gran número de características al modelo, aunque el valor de $R^2$ era alto en el conjunto de entrenamiento, se volvió negativo en el conjunto de validación y en el conjunto de pruebas lo cual muestra que este enfoque en realidad no funciona."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso\n",
    "\n",
    "Finalmente se decidió probar con regresión Lasso. La razón para probar esta regresión es que el criterio de umbral de varianza parecia sugerir que al eliminar coeficientes se lograba un modelo correcto. \n",
    "\n",
    "Lasso elimina coeficientes de aquellas características que podrían catalogarse de menor importancia, es decir, que tienen menor influencia en la respuesta.\n",
    "\n",
    "Se hizo una búsqueda semi-manual del parámetro $\\alpha$ que maximizara $R^2$ sobre el conjunto de pruebas. La búsqueda se realizó en el rango $[10^{100},10^0]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#alphas_ = np.logspace(100,10,base=10)\n",
    "#alphas_ = np.logspace(10,0,base=10,num=10)\n",
    "#alphas_ = np.logspace(3,5,base=10,num=10)\n",
    "#alphas_ = np.arange(1000.,4000.,500).tolist()\n",
    "alphas_ = np.arange(1000.,4000.,500).tolist()\n",
    "model = lm.Lasso(fit_intercept = False)\n",
    "for a in alphas_:\n",
    "\tprint \"alpha=%f\"%a\n",
    "\tmodel.set_params(alpha=a)\n",
    "\tmodel.fit(X,y)\n",
    "\tprint \"training R2=%f\"%model.score(X,y)\n",
    "\tprint \"validate R2=%f\"%model.score(Xv,yv)\n",
    "\tprint \"test R2=%f\"%model.score(Xt,yt)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "...\n",
    "alpha=1500.000000\n",
    "training R2=0.999961\n",
    "validate R2=0.536099\n",
    "test R2=0.540964\n",
    "alpha=2000.000000\n",
    "training R2=0.999931\n",
    "validate R2=0.543443\n",
    "test R2=0.546293\n",
    "alpha=2500.000000\n",
    "training R2=0.999892\n",
    "validate R2=0.548085\n",
    "test R2=0.543148\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que el máximo valor de $R^2$ que obtiene Lasso sobre el conjunto de pruebas es de $R^2 = 0.546$ para $alpha = 2000$ lo cual esta por debajo del modelo de regresión lineal. Es cuestionable que $R^2$ cambie significativamente en la vecindad del valor de $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "Se probaron diferentes enfoques los que obtuvieron diferentes valores para el coeficiente de determinación. \n",
    "\n",
    "Al aplicar un modelo de regresión lineal directamente sobre el modelo se obtuvo un coeficiente de determinación base de $0.590$ sobre el conjunto de pruebas. Se intentó mejorar sobre este con distintos enfoques.\n",
    "\n",
    "El primer enfoque de Umbral de Varianza consistía en eliminar aquellas características con una varianza menor a cierto umbral. Al aplicar este criterio se logró reducir el número de características de 145265 a 58685, mejorando el valor de $R^2$ sobre el conjunto de pruebas marginalmente a $R^2 = 0.594$. \n",
    "\n",
    "Un problema es la eficiencia de la solución debido al tamaño de la entrada, con esto se puede ver que incluso reduciendo el número de características significativamente se puede mantener un $R^2$ similar a usar todo el conjunto para construir el modelo. \n",
    "\n",
    "El segundo enfoque consistió en aplicar FSS eligiendo aquella característica con el mayor coeficiente asociado. Este enfoque consiguió un mal resultado con un $R^2$ que era retornado como negativo por lo que probablemente el modelo resultante podría considerarse invalido.\n",
    "\n",
    "El tercero enfoque fue aplicar regresión Lasso. Lasso no logró mejorar el coeficiente de determinación base encontrando un $R^2 = 0.546$ para $\\alpha = 2000$.\n",
    "\n",
    "Probablemente se deba trabajar con una combinación de otros enfoques distintos y con el umbral de varianza que es el que obtuvo resultados decentes. Quizás sea razonable probar otros criterios para la selección de características en Forward Stepwise Selection o probar otros enfoques de selección de características.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
